
var documents = [{
    "id": 0,
    "url": "/gallery/2015",
    "title": "Photo Gallery - 2015",
    "body": "           "
    }, {
    "id": 1,
    "url": "/gallery/2016",
    "title": "Photo Gallery - 2016",
    "body": "   "
    }, {
    "id": 2,
    "url": "/gallery/2017",
    "title": "Photo Gallery - 2017",
    "body": "          "
    }, {
    "id": 3,
    "url": "/gallery/2018",
    "title": "Photo Gallery - 2018",
    "body": "        "
    }, {
    "id": 4,
    "url": "/gallery/2019",
    "title": "Photo Gallery - 2019",
    "body": "                     "
    }, {
    "id": 5,
    "url": "/gallery/2020",
    "title": "Photo Gallery - 2020",
    "body": "                                      "
    }, {
    "id": 6,
    "url": "/gallery/2021",
    "title": "Photo Gallery - 2021",
    "body": "                       "
    }, {
    "id": 7,
    "url": "/404.html",
    "title": "404",
    "body": "404 Page not found!Please use the search bar from the bottom left or visit our homepage! "
    }, {
    "id": 8,
    "url": "/about",
    "title": "Brain@Light Focus: sudo rm -rf /",
    "body": "This website is a place where I write down some blogs about my personal experience, my understanding on some of the technologies. Hope you enjoy this site.  Find me on GitHub → "
    }, {
    "id": 9,
    "url": "/authors",
    "title": "Authors",
    "body": "{% for author in site. authors %}                       {% if author[1]. gravatar %}                {% else %}                {% endif %}                  {% if author[1]. web %}                       {% endif %}          {% if author[1]. twitter %}                      {% endif %}          {% if author[1]. email %}                      {% endif %}                                     {{ author[1]. display_name }}:         {{ author[1]. description }}                {% endfor %}"
    }, {
    "id": 10,
    "url": "/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 11,
    "url": "/contact",
    "title": "Contact",
    "body": "  Please send your message to {{site. name}}. I will reply as soon as possible!   "
    }, {
    "id": 12,
    "url": "/gallery",
    "title": "Photo Gallery",
    "body": "2021202020192018201720162015"
    }, {
    "id": 13,
    "url": "/",
    "title": "Home",
    "body": "  {% for post in paginator. posts %}    {% include postbox. html %}  {% endfor %}  {% include pagination. html %}"
    }, {
    "id": 14,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 15,
    "url": "/page2/",
    "title": "Home",
    "body": "  {% for post in paginator. posts %}    {% include postbox. html %}  {% endfor %}  {% include pagination. html %}"
    }, {
    "id": 16,
    "url": "/Revisit-on-photography-gears-Ive-used/",
    "title": "Revisit on Photography Gears I've Used",
    "body": "2021/09/06 - You can find photos I took hereI started photography back in late 2014 when I picked up gears my dad no longer uses. I had a Nikon D200 and three lenses: Nikon 17-35mm f/2. 8D, Nikon 80-200mm f/2. 8D, and Nikon 105mm f/2. 8G Micro. Although they were already pretty outdated back in 2014, they taught me the basics of photography, things like aperture, shutter speed, and ISO. I used D200 for a little more than half a year and took some pictures of landscapes, flowers, and black-headed gulls that migration to Kunming (where I live) every year. The D200 only has 10 megapixels and the back LCD screen is very low-res, so I couldn’t check if my photos were in focus or if there was any motion blur. Meanwhile, I’m in the early stage of photography, so I’m satisfied with a few photos taken on D200. In June 2015, I got the chance for a new camera. Since I’m on a budget, I got myself an entry-level full-frame camera with a kit lens: Nikon D610 and Nikon 24-120mm f/4G. Why a full-frame camera and a standard zoom lens you may ask? Full frame camera was of course for really making use of these full-frame lenses, I never knew what 17mm was like on full-frame. As for the standard zoom lens, I really needed a one-lens solution when I went out. I usually needed to carry two lenses, because 17-35mm was a little bit limiting on the long end. I also tried a flash but didn’t quite get the hang of how to use flash. Before high school graduation in June 2016, I mainly used this camera for events in high school, although I did take it on a trip to Thailand. During high school, I learned the basics of photography and my camera captured so much precious memory. Since I didn’t have spare time, my skills didn’t quite level-up. My high school was pretty close to my home so bringing a DSLR (Digital Single-lens Reflex Camera) to school wasn’t a huge deal. But my university was quite far from my home plus we didn’t have many class events going on so I wasn’t willing to take my camera there. I took way fewer photos during 2016-2017 and that’s why I decided to sell some gears I didn’t use much. I ended up keeping only the 24-120mm and 80-200mm. By the way, I used the money I got from selling those gears for a new MacBook Pro and that was probably one of the best purchases I ever made. I went to Japan in the summer of 2017 and before that trip, I purchased a Nikon 50mm f/1. 8G as a supplement of 24-120mm. This was my first time using a prime lens (except that macro lens). However, unlike many other people, I didn’t get blown away by that shallow depth of field, but I did like the compactness of the prime lenses. As for the trip, I had to admit that Japan is a fantastic place for taking photos, I took quite a few great photos there. The only problem I had was, after carrying the camera in a bag with a rather poorly-design load system, I started to feel that DSLR was too bulky. That’s when I turned my focus on mirrorless cameras. I wasn’t quite sure about the image quality of mirrorless cameras. Therefore, the first thought that struck me was buying a mirrorless camera as a back-up camera so that whenever I needed to travel light, I took the mirrorless camera. After a little bit of research, I came to the conclusion that mirrorless cameras are as good as DSLRs in most aspects. So I decided to ditch all my camera gears in exchange for the mirrorless system. I decided to go for Sony APS-C (Advanced Photo System type-C) cameras because I heard they have the best AF (Auto Focus) system. In the cold winter of 2018, I cleared out all my gears and brought a Sony A6300 with Sony 16-50mm f/3. 5-5. 6 kit lens and a second-hand Zeiss Batis 25mm f/2. Carrying a camera wasn’t a pain anymore. However, there are some compromises. Since the camera is quite small, the handling and the battery life are quite worse compared to DSLR. What’s also interesting was that I didn’t quite like the EVF (Electronic Viewfinder) at first. I felt it’s very low-res compared to OVF (Optical Viewfinder) so I wasn’t confident about the image I took until I saw the photos on my computer. And that Zeiss lens became a 35mm-ish equivalent lens on an APS-C camera and I quickly fall in love with the 35mm focal length. After a while with this lens, I felt like this lens was a kind of waste on an APS-C camera. So I sold it and got myself a Sigma 16mm f/1. 4 and a better Sony 18-135mm f/3. 5-5. 6 kit lens. That 18-135mm lens was a newly released one at the time so it’s sharp for a travel zoom lens. The best part was, this lens was sold as a kit lens with A6300 so you could get an amazing price if you buy the open-box version. I really liked this lens, compact, great zoom range, relatively sharp, and has some macro capability. The only downside I would say is the slow maximum aperture so I had to crank my ISO up. The Sigma 16mm prime is also pretty good. This is my first time using an f/1. 4 lens and I was often amazed by the low ISO value I could shoot with. Nevertheless, it’s kind of bulky on an APS-C camera. I took these two lenses to Thailand (again) in 2018 and they served me just right. I had no complaint whatsoever about them. But we all know what’s wrong with Sony APS-C cameras. They don’t have good color science, lack a front control dial and most importantly, there aren’t many APS-C lenses. Naturally, I looked for Fujifilm cameras as they have good color and probably the most extensive line of APS-C lenses. I got a Fujifilm X-T2 alone with a wide-angle Fujifilm 10-24mm f/4 lens and a Fujifilm 35mm f/1. 4 lens. Granted, many people liked Fujifilm for its retro design and its film simulation. However, I didn’t think they’re overwhelmingly better than the competitions. That retro design means no large grip and ok-ish handling. The X-Trans sensor Fujifilm uses, I actually found it has an impact on the fine detail on my images. If you zoom in, you’ll find some worm-like patterns. Moreover, since I shoot only RAW, good color means little to nothing for me. To be fair, that 35mm 1. 4 lens is very compact and produces some amazing photos. The only disadvantage would be that slow and noisy AF system. As for the 10-24mm lens, I think there is nothing to write home about. Since I was not happy about the image quality of the Fujifilm camera, I quickly sold it after only about 4 months of use. And this time I wanted to try a full-frame mirrorless camera. Unfortunately, my budget was tight so I could only get a Sony A7R2 and a Sony 24-105mm f/4 lens. The A7R2 was criticized for many things like its short battery life and slow AF, but at least it got that 42 megapixels sensor. I got to say its image quality blew me away. From high ISO to dynamic range, everything that comes from that sensor is simply amazing. Ok, maybe not the color. But you did feel all those shortcomings of A7R2 whenever you use it. Since I mainly shoot landscapes and slice of life, I didn’t bother too much by the AF speed. Just bring an extra battery and you’ll just be fine. Let’s talk about that 24-105mm lens for a while. Simply put, it’s the best 24-105mm lens on the market. It’s very sharp, focuses quickly, and has a better minimal focus distance which means it’s useful when you want to shoot some small objects. Unfortunately, it’s also a tad expensive than the competitions. Remember how I liked the 35mm focal length when I used the Zeiss lens? Well, I thought it’s a good time to introduce myself with the 35mm focal length again so I brought a Sony 35mm f/2. 8 ZA lens. Apart from 35mm, I brought it for its extremely compact size. F/2. 8 may sound slow for a prime lens but really, I didn’t need the shallow depth of field and the camera has good high ISO performance. Anyway, it quickly became the go-to lens for me. By far, I’ve used both APS-C and full-frame systems, but there was one thing left, M43 (Micro Four-Thirds). I was interested in this system when I did the research for mirrorless cameras back in late 2017, but I never really fall for it fearing its small sensor size would have too much impact on the image quality. One day, I came across a photographer online that used purely M43 cameras. I really like his photos and found no sign of unacceptable image quality. After reading his blog and did some research myself, I did something that sounds crazy. I sold my full-frame camera and brought an M43 camera. I had two choices at the time with identical price points: Olympus E-M1 Mark II or Panasonic G9. I ended up choosing the latter one for its better video capability. The funny thing was, I never shot a single video on G9 but the G9 tended to be the model with more resell value half a year later so I do not regret it. Together with G9 were two lenses: Panasonic Leica 12-60mm f/2. 8-4  and Panasonic 45-150mm f/4-5. 6. The very first thing I found out was that 12-60mm on the G9 is fantastic. The SOOC (Straight Out of Camera) color is the best I’ve ever seen. This lens also has a shocking 0. 6x maximum magnification on the telephoto end so it could act as a macro lens. The 45-150mm was also very useful, it was very affordable while providing the 300mm equivalent field of view. Albeit slow as far as the aperture is concerned. Now let’s talk about things I never experienced on previous cameras. First is that fully articulating screen. It’s very useful when you want to shoot from different angles although sometimes the traditional tilt screen may be more useful. The second is IBIS (In-body Image Stabilization), A7R2 has this but it’s lackluster. The IBIS on G9 is insane, I could handheld the camera for two seconds and still get sharp images. This is simply out of question on A7R2. Due to the longer exposure time, I found myself uses ISO 200 quite often, so the weak high ISO performance of M43 cameras is kind of eliminated here. To be honest, M43 systems are the best system I’ve got my hands on. It got an extensive yet affordable lens lineup, and the portability plus IBIS makes it a travel-friendly system. Unfortunately, Panasonic and Olympus didn’t play the cards well. M43 systems are going to an end sooner than everyone thought. As much as I liked M43, I couldn’t invest more in a dying system. And this time, I went for the final mainstream brand I didn’t try before: Canon. Canon is being bashed all these years for its outdated sensor technology and I brought the least advanced of them, the Canon EOS RP. This camera although has the same sensor as that on Canon 6D Mark II, is a more affordable model. While it’s entry-level and you could definitely tell from its build quality, at least you get a fully articulating screen and a comfortable grip. The lenses I got with the camera were Canon RF 24-105 f/4 and Canon RF 35mm f/1. 8 Macro. The 24-105mm is nothing special so I’ll skip it. The 35mm lens, on the other hand, provides you 0. 5x magnification in a consumer-level lens which is unseen before. This lens is relatively cheap and compact, but I really hated the noisy and slow AF system. Another benefit with Canon mirrorless cameras is you get to use EF lenses in native AF speed. Therefore, I also got the chance to play with Canon EF 16-35mm f/2. 8 L II, Canon EF 70-300mm f4-5. 6 L, and Canon EF 100-400mm f/4. 5-5. 6 L II. All these lenses are superb except that 70-300mm is a bad copy but anyway I had some quite lovely pictures with them. I took a trip mainly for photography to Chongqing in late 2020 and I started to feel the importance of telephoto lenses in traveling. However, telephoto lenses are usually very heavy so we tend to leave them at home. Therefore I start to seek light telephoto lenses. While searching, one lens popped into my eyes: Tamron 28-200mm f/2. 8-5. 6. Yes, it’s a super zoom lens but hey, it’s compact and got a relatively bright aperture, and most importantly, its image quality is good for a super zoom lens. Some people complained but not having 24mm but for me, if 28mm isn’t wide enough, neither is 24mm. Just get yourself another wide-angle lens. And here we go again, I sold all Canon gears and got a Sony A7R3 and this Tamron 28-200mm lens. I was quite happy with this combo. I got the same, if not better, image quality as A7R2 while having better handling and battery life. And the quality of this lens is also quite satisfying. You get decent magnification, f/2. 8 at 28mm and you can zoom all the way up to 200mm while this combo is just 1. 2kg. I would say that A7R3 is the first camera I would not feel like ‘wanting for more’. For the next few years, I’d like to invest more in lenses. The Sony FE mount really has the best lens lineup right now, and I can’t wait to play some of them. – Update on 2021. 9. 6 – As I said before, having an ultra-wide lens is a good combo for 28-200 which is why I bought Tamron 17-28 f/2. 8 lenses. It’s relatively cheap, has a constant f/2. 8 aperture, and is really lightweight. It compromised on the focal range but it makes a perfect combo with 28-200 as there’s no overlapping between the two. With coverage from 17mm all the way to 200mm, it’s safe to say that they satisfy 95% of my photography. Not to mention the whole setup weighs only 1. 7kg. I would only miss a third lens when I need more than 200mm but hey, I can always crop my image as I have 42 megapixels. Finally, after using all these gears, I would like to do a sum-up. The following content refers to mirrorless cameras only. Micro Four-Thirds:: It’s a very fun system to play with. But it’s dying so I can’t recommend anyone to invest in it. If you got the money, definitely try it if you haven’t. APS-C:: Sony:: Awful handling, lack of IBIS, short battery life(except A6600). The good news is that now Tamron starts to make lenses for Sony APS-C cameras. You can now have Tamron 11-20 f/2. 8, Tamron 17-70 f/2. 8 paired with Sony own 70-350 f/4. 5-6. 3 G lenses and you’re all covered. Fujifilm:: Great for the beginner as it has good SOOC color and the dials on the top are good demonstrations of the basics of photography, let alone retro design. If you mainly play with RAW, I wouldn’t recommend it as X-Trans tends to be a bit soft compared to traditional Beyer Sensor. Also, lacking third-party lenses means you need to pay more money on the lenses. Canon:: While handling is better, it is the same as the Sony system where lenses are a real problem. I mean at least Sony APS-C users can use their full-frame lenses. Canon EF-M mount? That’s a joke. (Still, many people buy it for the color) Full-frame:: Sony:: Handling and IBIS are average, the interface is terrible, but that’s basically it. Many affordable third-party lenses to choose from and the sensor image quality is top-notch. Canon:: Canon really knows how to make a comfortable grip and their glasses are the best in the class. If you got the budget or like the ‘Canon color’, go for it. Nikon:: Unless you got a bunch of Nikon F glass, I wouldn’t recommend it. "
    }, {
    "id": 17,
    "url": "/What-Makes-Apple-Ecosystem-So-Special/",
    "title": "What Makes Apple Ecosystem So Special",
    "body": "2021/01/14 - Whether you heard this before or not, Apple is famous for its ecosystem. Simply put, their devices tend to work together for better integrity. In this post, I’d like to introduce some of these features that build up the Apple ecosystem. If you happen to have a bunch of Apple devices in your hand, then you are in for a treat. Between multi-devices:: Now, iPhone is probably your first Apple device. And truth to be told, iPhone is the key to the Apple ecosystem because we do have iPhone exclusive features like phone calls and text messages. So the first thing that comes to mind would be calls and messages on iPads and Macs, which Apple calls iPhone Cellular Calls and Text Message Forwarding. Once set up, you may hear all your devices ring at the same time when you have an incoming call. And there are more, like Universal Clipboard and Handoff. The first one is pretty self-explained. As its name suggests, we can have a universal clipboard that shares between these devices, so you can copy something on your Mac and paste it on your iPhone. Handoff is rather interesting. If you opened a webpage and didn’t finish reading it, you can open it on your iPhone and pick up where you’ve left on the go. What if I want to send a file or a photo? No problem, use AirDrop. It quickly finds what devices are around you. You simply tap the icon, and off you go. Best part? No data plan is needed. While we’re talking about photos, why not enjoy them on a large TV screen? You can use AirPlay to mirror your iPhone or Mac screen on Apple TV. But AirPlay does more than that. For example, you can also share audio between devices. And for those who are forgetful, you can use the Keychain feature. It stores all your passwords, and you are just one autofill away from your passwords. This also works for Wi-Fi passwords. You can automatically connect to Wi-Fi if your other devices connected before. Now, most of these features require an Apple ID with the free iCloud plan. If you’re willing to pay more, you can also use iCloud Drive, a cloud disk that allows you to store your files and get them instantly on any device. Don’t worry because we are far from completing this post. Now, let’s talk about features that are specific to some devices. Between iPhones and Apple Watches:: They’re born to be a pair. You get all notifications from your iPhone on your wrist. While the iPhone reads all health data on your watch. Between iPhones and Macs:: You can use your iPhone’s camera to take photos and import them directly to your Mac. Of course, you can also use your iPad, but I just feel more natural to take pictures on iPhones. Between iPad and Macs:: People like iPads for their large screens, so they’re perfect extensions for your Mac. That’s why with Sidecar, you can mirror or extend your Mac desktop. One thing unique about iPads is you get to use Apple Pencil, a fantastic input device. Therefore, you can use the iPad as a drawing pad for Macs while extending the workspace on your Mac. Between Apple Watch and Macs:: Say no more to your unlocking password. Your Apple Watch can unlock your Mac when you’re near your Mac. This also works when the software is asking for the password. Simply double press the button on Apple Watch. So there you have it. Some of these features may not be Apple-exclusive but let’s be honest, Apple makes them more intuitive. As the slogan suggests: It just works. "
    }, {
    "id": 18,
    "url": "/Photography-101/",
    "title": "Photography 101",
    "body": "2021/01/11 - Taking a photo on a smartphone may seem easy, but that’s because smartphones take care of many complicated things so you just need to press the button. In this post, I’d like to talk about some basics of photography so without the help of smartphones, you can still get some nice pictures. First things first, let’s talk about the ‘brightness’ of a photo, which we call ‘exposure’. If a photo is too dark, we call it ‘underexposed’, on the opposite, we call it ‘overexposed’. So what determines the exposure of a photo? How much light you have of course. But in many situations, we can’t control the light source, but we can adjust our cameras to get the exposure we need. Three things affect your exposure: aperture, shutter speed, and ISO. Aperture is a hole-like mechanism in the lens that controls how much light will come through the lens. A smaller aperture means less light and vice versa. We describe aperture in f-numbers, something like f/1. 4 or f/2. For a 50mm focal length lens, if its f-number is f/2, it means the hole for the light comes in is 50/2 = 25mm wide. Therefore, a smaller number actually means a bigger aperture. And every time the f-number is multiplied by the square root of 2 or roughly 1. 4, the brightness is halved because only half the light can come in. For example, f/1 is two times brighter than f/1. 4. Shutter speed means how long your shutter opens, the longer the shutter opens, the more light hits the sensor so your image will look brighter. The shutter is also used to control movement, a fast shutter can freeze movement while a slower shutter can cause motion blur. ISO, aka sensitivity, measures how sensitive your sensor is to the light. No matter you’re shooting with a film or digital camera, the higher the ISO is, the more noise your image will have. These three things are in a triangle, so if one is changed, another has to be changed as well to maintain the same exposure. For example, in the same environment, a photo shot with f/1, 1/100 s, ISO 100 has the same exposure as a photo shot with f/2, 1/25 s, ISO 100. So there can be thousands of different combinations of these three values?Yes, but we need to think about how these values will also affect things other than exposure. Aperture also affects depth of field, or how much things are in focus in your photo. A bigger aperture results in a shallower depth of field which is good for portrait photos when you want to blur those backgrounds. A smaller aperture, however, makes more things in focus so it’s good for things like landscapes. Choose your aperture accordingly based on your topic. Shutter speed, as we’ve talked about, affects movement. If you’re shooting sports or wildlife, you definitely want a fast shutter speed. A slower shutter speed is useful when you want to smooth a waterfall for example. One thing to keep in mind is that when you use a slower shutter speed, your handshake will likely ruin the photo. That’s why we need a tripod to stabilize your camera. ISO will affect your image quality, so unless the former two things are limiting, don’t crank your ISO up. So there you have it, you’ve learned how to take a photo with the correct exposure if your camera doesn’t get the job done for you. Since autofocus is so advanced these days, I think I’ll just skip this part as beginners can rely on the autofocus without any concerns. The last thing I’d like to address is composition, but I’ll not go too deep into this topic as this is a 101 lesson. Composition is a term to describe how you arrange your subjects in your photo. Naturally, we’d like to put our subject in the center of the frame and that’s totally fine. It’s just that sometimes it can be quite boring to look at, so there’re plenty of ways to composite your photos, like the famous rule of thirds. Now you know how to correct your exposure, control the depth of field and movement, you also have the concept of composition in your mind. Give them a try and see if you can take some different pictures. "
    }, {
    "id": 19,
    "url": "/Color-in-Computer/",
    "title": "计算机色彩相关知识简介",
    "body": "2020/08/24 - 色彩表示方法: 人对于色彩的描述是很不准确的。 以上面这个图片为例，人们都会将它们描述为红色，但是在计算机的表示里面，它们是完全不同的四个颜色。 计算机里面有很多种表示色彩的方法，一般人最耳熟能详的就是RGB色彩模型。RGB是一种加色模型，即红蓝绿三种原色光相加来获得其他颜色的光。选择红蓝绿三种颜色是因为这三种颜色能分别对人的三种锥形细胞产生刺激，虽然这些细胞并不是对这三种颜色的光最敏感。 RGB模型可以写成很多形式。以白色为例，可以写成(1. 0,1. 0,1. 0)、(255,255,255)、(100%,100%,100%)等。但是我们很快就可以看出，RGB模型和显示设备的色彩空间有很大的关系，不同的设备显示的RGB(255,255,255)是不同的。 RGB色彩模型理论上可以显示256*256*256种颜色，即16777216种颜色，也就是我们常说的1600万色。但是在网页显示中，为了防止这1600多万种色彩产生混淆，我们引入了网页安全颜色。 RGB色彩模型虽然很常用，但是它也有一定的缺点，最明显的一点就是人不能直观的理解。例如黄色的RGB值就不能第一时间想到，除非你对三色光相加很熟悉。因此，我们引入了人看上去更为直观的HSL/HSV色彩模型。 虽然乍一看HSV/HSL有些复杂，但是它更直观。其中H（Hue）代表色相，是一个圆形，通过角度来表示颜色；S（Saturation）代表饱和度，圆柱体中间饱和度最低，边缘饱和度最高；V（Value）/L（Lightness）代表亮度，圆柱体越往上越亮。在这种色彩表示模型下，一切就变得很直观。例如（60°,1. 0,1. 0）就可以理解为最亮最饱和的黄色。HSL/HSV模型被更多的用于设计方面，例如摄影的调色就可以采用这种模型，因为调整起来更好理解。 一般来说HSV/HSL色彩模型只是用于表示，而计算机最后显示的都是采用RGB色彩模型。因此不可避免的就是HSV/HSL与RGB之间的转换。每一种转换都有对应的数学公式，这里不展开讨论。 除此之外，还有一种色彩模型也很常用，那就是CMYK模型。这种模型主要用于印刷行业，因为打印机一般只有黑色（K:Black）和三色墨盒（C:Cyan, M:Magenta, Y:Yellow）。类似的，按不同比例混合这些颜色也能得到不同的颜色。 在介绍完了常见的色彩模型后，我们需要提一下色彩空间。很多人对“色域”（Gamut）这个词比较熟悉，色彩空间其实就是由色域和色彩模型共同定义的。很多人会把色域和色彩空间混为一谈，因为他们默认色彩模型是RGB模型。常见的色彩空间有sRGB、P3、Adobe RGB等。 一种最常见的对比色彩空间的方法就是将色彩空间在 CIE1931 xy色彩图上表现出来。CIE1931色彩空间是最早采用数学定义的色彩空间，是一个三维空间。但是为了方便表示，人们习惯将其投影到平面上，采用xy的形式表示，形状类似于一个舌头。 上图的E点表示均等能量点，又称为白点。当我们需要表示一种色彩空间的时候，将其边界在CIE1931中绘制出来就可以了。 最后要提一点的就是色度抽样，其主要用于对图片或者视频进行压缩。其原理是利用人眼对于色彩的敏感度远低于对亮度的敏感度，因此可以压缩图片中的色彩信息而保留亮度信息，以达到基本不损失视觉效果的前提下压缩体积。 以上图为例，上面一排图片看上去的视觉效果差不多，而下面一排可以明显看出色彩信息的分辨率不一样。 计算机色度抽样通常使用一个三分比值表示：J:a:b，其中J表示区域的长为J个像素，高为2个像素，J一般为4；a表示在J个像素的第一行的色度抽样数，b表示在J个像素的第二行的额外色度抽样数。有些时候会有第四个数Alpha，表示水平因素，没有时可忽略，存在时和J相同。 下面列出几种比较常见的色度抽样： 绝大部分经过压缩的图片和视频都会采用色度抽样的方法，因此我们看到的颜色不一定是原始数据所反映的颜色。 以上就是本文要介绍的计算机色彩的基本知识。 "
    }, {
    "id": 20,
    "url": "/Introduction-to-Git/",
    "title": "Introduction to Git",
    "body": "2020/08/21 - As long as you work on computers, you’re likely running into a situation where you need to constantly modify a file or a folder. Problem is that when you want to check what it was like 3 days ago or you want to undo your modification, things will get tricky. That’s when version control comes to our aid. Git is a very popular distributed version control software. Note the word “distributed”, meaning that it will not only work locally on your computer but also can be used remotely. Since Git is a command-line based tool, you need to learn the syntax to make the best use of it. Before we dive into the commands, let’s take a look at the bigger picture. If we want to use Git in our project, go into the working folder and type in the command “git init” to initialize git so it knows the scope of which files need to be tracked.  After initialization, we can use the command “git status” to verify the current status of git, which in this case, you can see all files haven’t been added to git. Whenever you want to check the status, you can use this command.  To add these files to git, we will use the command “git add . ” where the dot means all files. This will add all files within the scope of git to the “stage” where you can later decide whether you want to add them into the branch. Alternatively, you can use “git add &lt;filename&gt;” to add the specific file you want to add.  Once we confirm all files in the stage need to be committed to the branch, we type in “git commit -m your commit”. If we use the command “git log”, we can see all the commits we’ve done so far.  Since Git tracks all the commits, you can easily revert to the previous commit if you wish. Notice every commit has a long special number, we can use that number to clarify which commit we want to revert to. Type in “git reset &lt;commit number&gt;” and off you go.  Another important feature of version control is to be able to work on different branches. If I have an idea but I’m not sure if it will be in the final project, I can use branches to experiment with my idea without affecting the master branch. By default, you’re working on the master branch. You can make new branches by typing “git branch &lt;branchname&gt;”. If you’re not sure which branch you’re working on, you can use the command “git branch” to check it out, the branch you’re on indicates by an asterisk.  To move between branches, type in “git checkout &lt;branchname&gt;”.  When you’re satisfied with your branch and want to merge it with the current branch, you can use the command “git merge &lt;branchname&gt;”.  Now you know what to do when you add or modify files, more importantly when you want to undo the changes or make a branch. That wraps up the basics of git on your local computer. But remember we talked about “distributed”, so let’s talk about the remote capability of git next. To simplify this post, we only talk about the most common commands you need to use. When you want to publish your git project online, you first need to specify where you want to put by using the command “git remote add &lt;name&gt; &lt;url&gt;” where we used to name it “origin”, but choose your name anyway. After that, we need to push our git project to the Internet. Type in “git push &lt;remote&gt; &lt;branch&gt;” where &lt;remote&gt; is the name you give and &lt;branch&gt; specifies the branch you want to push, usually master. Similarly, if we want to update our local project from the online repositories, we can use “git pull &lt;remote&gt;”. This will automatically merge the online files with your local files. But there is one more thing. What if we want to get a copy of other people’s git project? We can simply use “git clone &lt;repo&gt;” where &lt;repo&gt; is usually a URL of the repository ends with “. git”. If you want to learn more about Git, here is the cheatsheet that you can work on. So there you have it. Now you can make use of the most popular version control software and hopefully it can make your life easier. "
    }, {
    "id": 21,
    "url": "/Apple-Silicons/",
    "title": "The history of Apple Silicons",
    "body": "2020/08/21 - Before A series chip, there were. . . The original iPhone was announced in 2007 when the chip it uses was not developed by Apple. 4 chips were used in a variety of products before the introduction of the A4 chip in 2010. APL0098: 90mm chip, single-core, 412MHz frequency make this chip outdated but this is where the original iPhone started with. This chip was used on the original iPhone and iPhone 3G as well as the original iPod Touch. It’s worth mentioning that this is the only 16-bit chip in this post. APL0278: This was announced several mouthes after iPhone 3G and was used on the 2nd generation of iPod Touch. It’s basically an APL0098 with an updated process to 65 nm which reduces its die size to half and brings an even higher clock speed. The most important update is 32-bit memory addressing. APL0298: Compared with the original chip, its clock speed is 50% higher, which proves the “S” in iPhone 3GS is “Speed”. APL2298: The last chip not designed by Apple, 45 nm process. Higher frequency brings the 3rd gen iPod Touch more performance. This changes everything. Again. 2010 comes the iPhone 4. Just like the ad says, iPhone 4 changes what a phone can do. Why? The Apple-designed chip definitely plays a big part in it. Moreover, no one knows what such a money-costing development can bring to Apple in the future. A4: It’s a lackluster chip if you look at its spec, same 45 nm process, slightly higher frequency, the biggest update is probably dual-channel memory. But don’t forget, iPhone 4 is the first product that utilizes Retina Display which has 4 times more pixels than the predecessor. This is a satisfying result. A5 &amp; A5X: A5 focuses on one thing: performance. More than twice the die size brings the first dual-core chip designed by Apple. At the same time, GPU was upgraded to PowerVR SGX543MP2 which brings 7 times more performance, it’s unprecedented. If you remembered the keynote of the iPhone 4S, after the introduction of the A5 chip was the live demo of Infinity Blade II by Epic Games. Many desktop-level effects like particle effects, dynamic lighting were brought to mobile devices for the first time. This gives hope for future Apple chips. A5 also integrated an image signal processing unit for the first time which enhances the camera on iPhone 4S. But the story of A5 does not stop here. Since the Retina Display on iPhone was so popular, Apple wanted to bring this to the iPad. However, iPad has 5 times more pixels than iPhone which was not possible with the A5 chip. Considering iPad has more physical room and a bigger battery, Apple decided to upgrade the GPU on A5. And here came the A5X which has double the GPU performance of that on A5. Ever since then, chips ended with X are made specifically for iPad with better GPU performance. A6 &amp; A6X: It’s a scheduled upgrade so not too many highlights except the 32 nm process. Due to the large time gap in production, newer A5 chips also had a 32 nm process. World's first and only smartphonePC industrial spent many years to complete the transition from 32-bit to 64-bit, Apple took one generation of CPU. A7: iPhone 5S had special meaning as it’s the world’s first smartphone with a 64-bit CPU. This proves Apple’s leadership in chip design, but also proves that Apple wanted to make its chips more professional. Besides that, A7 also comes with M7, a co-op processor that can record sensor data without waking up A7. This allows recording health data without impact too much battery life. Since iPhone 5S is equipped with Touch ID, A7 also includes a secure enclave to protect fingerprint data. A7 may be too strong that Apple didn’t even release an A7X, but increased the frequency a bit and put it in the iPad Air. A8 &amp; A8X: Normal update. Perhaps considered that iPhone 6’s large screen impacts battery life too much, A8 focused on energy-saving which only uses half power as A7. A9 &amp; A9X: The last generation of dual-core chips which means single-core performance was reaching its limit, so we need to use more cores in the future. A9 has two versions, 14 nm from Samsung and 16 nm from TSMC that were both used in iPhone. In Oct. 2015, a report said that the Samsung version has worse battery life. A10 Fusion &amp; A10X Fusion: To preserve even more battery life, Apple for the first time used a big-small core architecture. 2 + 2 core configuration makes A10 have better battery life under light tasks. However, big and small cores cannot be used at the same time. Take it to the next level. 2017 marks the 10th anniversary of the iPhone, Apple announced iPhone X. The headline feature was of course Face ID. To achieve high security, Apple had to change its chip design again. A11 Bionic: Before A11, Apple only designs the CPU part, GPU still uses chips by PowerVR. This time, Apple makes both. Besides that, Apple added a neural engine in A11 which enabled hardware acceleration for deep learning. A new controller allows big and small cores to work at the same time which improves performance. A12 Bionic &amp; A12X Bionic: The neural engine made many new features possible and that’s why Apple updated it to enable 5000 billion calculations per second. A12 is also the first 7 nm chip used on the smartphone. A13 Bionic: Today, iPhone has a one-year advantage over Android phones in terms of performance. Sometimes it’s even closer to the desktop performance. Since Apple can integrate more functions into a chip, a dream 10 years ago is slowly becoming the reality. Those long divided shall be united. The world is unpredictable, Apple could have not imagined this 10 years ago. A12Z Bionic: June 24, 2010, iPhone 4 went on sale, marks the release of the first Apple-designed chip. 10 years later, on June 22, 2020, on WWDC 2020, Apple announced that future Macs will also use Apple-designed chips. The A12Z inside DTK is only one more GPU core than the A12X. Demo on WWDC is fairly promising as tasks like video editing, 3D rendering, and games are all working fluidly. Future chips will for sure be better than A12Z, so it’s very exciting. Looking back this 10 years, Apple made some exciting products with these chips. Apple probably only wants to apply their chips on iPhone in the very beginning, but as time goes by, Apple found that their chips were capable of doing many things, which led Apple to control all their production with Apple-designed chips. – Update on Sept. 6, 2021 – M1 chip used on the MacBook Air and MacBook Pro seems like a success as people found its performance amazing. The problem with M1 is mainly the lack of I/O and memory which shows this is an entry-level chip. I’m looking forward to the M2 chip that may come later this year. "
    }, {
    "id": 22,
    "url": "/Which-Mac-to-Buy/",
    "title": "Mac选购指南",
    "body": "2020/08/19 - 最后更新于2020. 8. 19: 在选购Mac之前，我们首先应该问问自己为什么要买Mac。如果不是因为macOS或者 logo的话，Windows阵营有更好的选择。 Apple在WWDC2020上宣布将于2020年开始由Intel Mac向Apple Silicon Mac过渡，为期两年，因此在这个时候购买Mac就成了一件麻烦事。如果你对Apple Silicon不熟悉的话，其实就是Apple一直在自家iPhone和iPad上用的自己研发的芯片。关于更多Apple Silicon的介绍和更换Apple Silicon能给Mac带来什么优势，可以移步这里。 简单来说，我的选择原则如下： 选择Intel Mac如果你： 1. 购买Mac是刚需 2. 需要在Mac上运行Windows 等待Apple Silicon Mac如果你： 1. 想获得更长的系统更新支持 2. 主要用Mac进行视频图像处理 确定了你需要一台Mac以后，我们可以利用下表根据自己的预算以及对便携性的需求快速选择出适合自己的机型。 性能较弱性能强劲笔记本MacBook AirMacBook Pro 13'MacBook Pro 16'台式机Mac MiniiMac 21. 5' / 27'iMac Pro / Mac Pro预算范围&lt;¥10000¥10000-16000&gt;¥19000注：Mac Mini &amp; Mac Pro不带显示器当然，因为每种机型里面还有不同的配置可选，所以下文详细展开每一项配置应该怎么选。 处理器：: 适合下列任务：编译、视频编码解码 推荐升级机型：MacBook Air的双核i3升级到四核i5（仅¥500），台式机根据自己需求升级 不推荐升级机型：所有MacBook Pro，价格高且因为散热问题性能提升有限 内存：: 适合下列任务：基本上所有任务，尤其是涉及到多开或者大型应用的情况，例如Chrome、FCPX 推荐升级机型：所有机型，对于经常修图、剪视频、写代码以及需要虚拟机的建议16G起步 存储设备：: 适合下列任务：所有松鼠囤积病患者 推荐升级机型：所有机型，如果需要装Windows建议至少512G起步 图形处理器（仅针对16寸MacBook Pro及除了Mac Mini的台式机）：: 适合下列任务：视频编码加速、游戏 推荐升级机型：除了Mac Pro上的高配显卡，其他性能都很一般，根据自己需求升级 其他：: 以太网（Mac Mini）：一般家庭用户没必要 Afterburner（Mac Pro）：到这个级别了应该很清楚自己的需求了 妙控鼠标和妙控板（台式机）：妙控鼠标手感不好、强烈建议妙控板+其他鼠标 预装软件：有学生资格的话五件套只要¥1298！ 一些简单对比4 Core MacBook Air vs 2 Thunderbolt MacBook Pro: 4C MacBook Air2TB MacBook ProCPUIntel Core i5 1030NG7Intel Core i5 8257U内存8G 3733 MHz8G 2133 MHz显卡Iris Plus G7Iris Plus 645固态硬盘256G256G重量1. 29 kg1. 4 kg价格84999999    乍一看好像MacBook Air便宜1500而且性能差不多，不过我们还是详细谈一谈二者的区别。 CPU方面，MacBook Pro还是强一些，Cinebench R15单核 159 vs 140，多核 638 vs 448。另外MacBook Air的散热是一个很大的问题，因为内部风扇和CPU之间没有直连，所以这个风扇相当于只是把空气吸入内部，然后CPU被动散热。 显卡两者差距不大，MacBook Pro小胜一筹。 屏幕方面，MacBook Pro支持P3色域而且亮度可达500nit，MacBook Air只支持sRGB色域而且亮度只有400nit，MacBook Pro完胜。 扬声器效果MacBook Pro好一些。 可能是因为电池比MacBook Pro小（58. 2Wh vs 49. 9Wh），MacBook Air的续航在浏览网页等轻量工作时稍短于MacBook Pro。 总结：这1500的差距主要体现在TouchBar、屏幕、扬声器以及更好的散热（虽然是五十步笑百步）。 2 Thunderbolt MacBook Pro 13' vs 4 Thunderbolt MacBook Pro 13': 简单来说，只要预算到位，强烈建议上4 Thunderbolt的MAcBook Pro，主要原因如下： 1、十代CPU vs 八代CPU 2、16G内存 512G固态硬盘起步 3、2个Thunderbolt口真的不够用 iMac Pro vs Mac Pro: 两者还是有很大一段价格重叠，不过定位完全不同。iMac Pro针对不喜欢折腾、桌面空间有限以及喜欢开箱即用的用户，后期扩展升级性低。而Mac Pro针对需要很强扩展性的用户，或者是那些需要自己选配顶级显示器的用户。 "
    }, {
    "id": 23,
    "url": "/What-Hardware-to-Buy/",
    "title": "自己装机硬件怎么选？",
    "body": "2020/08/19 - 装一台电脑可能对于很多人来说不是一件容易事，但其实它真的很简单。 本文先从最基本的硬件选购开始，介绍各个硬件、教你如何判断一个硬件的性能，以及选购的时候需要注意的事项。 一、CPUCPU作为电脑的大脑，肯定是要好好选。能选择的有两家：Intel、AMD，俗称红蓝厂。 自古红蓝出CP Intel和AMD可以说是老冤家了，从上个世纪就开始CPU市场的竞争，什么第一个64位处理器啊，第一个突破1GHz主频的CPU啊。在很长一段时间里，Intel都是吊打AMD的，只有便宜的电脑才会装AMD的CPU。而今天的故事还要从2014年说起。 2014年10月27日，Intel发布了Broadwell处理器，用上了14nm的制程。在处理器制程上的更新，Intel一直都是采用Tick-Tock策略，即一代提升制程，下一代优化，再下一代再提升制程，以此类推。例如：Penryn(45nm)-&gt;Nehalem(45nm)-&gt;Westmere(32nm)-&gt;Sandy Bridge(32nm)。从22nm的Haswell开始，Intel变成了Tick-Tock-Refresh的策略，也就是说一个制程用三年。但是让人没想到的是，2014年发布的14nm处理器，竟然让Intel用了Broadwell、Skylake、Kaby Lake、Kaby Lake R、Coffee Lake、Amber Lake、Comet Lake整整六代（我没有数错）处理器上。Intel自此也被人称为“牙膏厂”，因为新制程一直挤不出来。 AMD这边则是通过2017年发布的基于Zen架构的Ryzen开始翻身，从以前的性价比首选，到高端电脑也可以选。尤其是2019年发布的3代Ryzen，基于Zen2机构，赶在Intel之前实现了7nm制程。 因此，在Intel挤出桌面10nm牙膏之前，装机我个人推荐AMD的处理器。不过Intel的处理器在游戏方面可能更胜一筹，但是两者差距只有在100+fps时才体现的出来（即需要顶级显卡）。装黑苹果建议选择Intel。 选购CPU主要关注以下几个参数： 核心数：顾名思义，核心的数量，越多越快 线程数：一般等于核心数，具有超线程功能的CPU则等于核心数的两倍。 基准频率：一般运行的频率，越高速度越快 Boost频率：可以波动频率的最高值（非手动超频情况下） TDP：热设计功耗，和散热及电源的选择密切相关 下面列出Zen2架构的CPU（不包含HEDT平台） 型号售价MSRP($)核心数/线程数基准频率(GHz)Boost频率(GHz)TDP(W)入门级3100994/83. 63. 9653300X1204/83. 84. 365主流级3500X￥10996/63. 64. 16536001996/123. 64. 2653600X2496/123. 84. 4953600XT2496/123. 84. 595性能级3700X3298/163. 64. 4653800X3998/163. 94. 51053800XT3998/163. 94. 7105发烧级3900X49912/243. 84. 61053900XT49912/243. 84. 71053950X74916/323. 54. 7105建议预算4000以内装机的用户选择3300X，6000左右的选择3600，10000左右选择3700X。 二、主板选好CPU的同时也就确定了主板可选的范围。 以3代Ryzen为例，其接口为AM4，通过查询我们可以得知支持该接口的芯片组有： 型号PCI Express (PCIe)市场定位CPU 支持芯片组PCIe 通道数ZenZen+Zen 2Zen 3X570PCIe 4. 0 ×16性能级否是是是X470PCIe 2. 0 ×8是否X370需要BIOS 升级B550PCIe 3. 0 ×6主流级否否是是B450PCIe 2. 0 ×6是是否B350需要BIOS 升级A320PCIe 2. 0 ×4入门级不同芯片组的功能、可扩展性、对未来CPU的支持都不一样。对于可能要升级Zen3的用户值得考虑X570和B550，否则一般用户X470和B450也足够了，因为AM4接口只用到Zen3为止。后面更新的CPU又是新的接口要买新的主板。 除了芯片组以外，主板还有一个很关键的参数就是板型。板型决定了主板的大小以及接口数量。 常见的主板板型有：ATX（305mm*244mm）、microATX（244mm*244mm）、Mini-ITX（170mm*170mm）。 想要装一台体积小巧的电脑最佳选择肯定是Mini-ITX的主板，不过Mini-ITX主板一般价格稍贵而且通常只有个一个PCIe接口，所以Crossfire或者SLI就肯定不行了。 一般来说建议CPU和主板一起买，价格会比较优惠，而且对于部分老主板可以让卖家帮你刷好新的BIOS以保证CPU能正常工作。 三、显卡独立显卡并不是人人都需要。对于不需要太强劲显卡性能同时想省钱的用户可以考虑Intel带集成显卡的CPU或者AMD的APU系列，即把显卡集成在CPU里面。 目前3代Ryzen能买到的APU好像只有Ryzen 5 3400G。购买APU需要注意两个问题：1、APU的性能与内存息息相关，买APU的用户一定不能在内存上省钱 2、APU对黑苹果的支持有问题。 那么剩下的用户自然就是需要高性能独立显卡的了。类似的，独立显卡市场也是两大阵营，AMD和NVIDIA，俗称红绿厂，也是老冤家，这里就不展开叙述了。 AMD的显卡没有像它的CPU那么猛，吊打竞争对手。在高端显卡这块，还是NVIDIA一家独大。 AMD这边你能买到最好的显卡就是RX 5700 XT，略逊于NVIDIA的RTX 2070 Super。但是NVIDIA往上还有2080、2080super、2080ti呢。（这里不讨论Titan以及Vega II Duo） 新显卡的独家功能上，NVIDIA更吸引人。光线追踪、DLSS以及CUDA，AMD这边只有RIS比较有看头。注意：GTX 16xx显卡不支持光线追踪及DLSS。 关于上面功能的介绍请移步这里。 下面给出热门在售显卡的参考性能，可以根据实时价格对比购买。 GTX 1650 参考性能： PUBG(1080p Ultra): 60 fps Gears 5(1080p High): 60 fps Assassin’s Creed Odyssey(1080p Very High): 47 fps Metro Exodus(1080p High): 46 fps Red Dead Redemption 2(1080p Medium-High): 37 fps Battlefield 5(1080p Ultra): 54 fps Control(1080p High): 32 fps 型号相对性能（1080p）GTX 1650100%RX 570114%RX 5500129%RX 580131%RX 5500 XT132%GTX 1650 Super135%GTX 1660150%GTX 1660 Super168%GTX 1660 Ti172%RTX 2060202%RX 5700210%RTX 2060 Super227%RTX 2070235%RX 5700 XT241%RTX 2070 Super260%RTX 2080277%RTX 2080 Super294%RTX 2080 Ti324%在你选好了显卡以后，你会发现同一个型号，不同厂家的价格差距很大。同一型号内便宜的称为乞丐版，贵的称为顶级非公版。乞丐版会在供电、RGB以及散热上缩水，同时显卡的频率不如顶级非公版的高。在预算不足又想要高性能的前提下可以买丐版。例如2070 super丐版3300，顶级非公4000出头，但是2080super的丐版只要4300。这种情况下选择2080super丐版能获得更好的性能。 四、内存不考虑上古DDR3的话，买内存就三个重要指标：容量、频率、时序。 容量建议起步16G，上限看你插槽数量和钱包了。 频率对高帧率游戏以及APU影响明显，建议3200MHz往上。 对于Zen2架构的用户特别注意，3733MHz是内存延迟的Sweet Spot： 时序介绍起来比较复杂，对新手来说，记得第一位数字越小越好。因此3600MHz C16的内存比3600MHz C18的内存好。 RGB内存条性能翻倍 五、硬盘大体上分为三类：机械硬盘，SATA固态硬盘，NVMe固态硬盘 机械硬盘：使用SATA接口，内部是磁盘的传统硬盘，速度约100mb/s。: 优点：容量大，数据可以恢复 缺点：需要额外供电、体积大且重、抗震性差 SATA固态硬盘：使用SATA接口，内部是闪存的固态硬盘，速度约500mb/s。: 优点：不需要占用主板的m. 2接口 缺点：需要额外供电、价格稍高 NVMe固态硬盘：使用m. 2接口，内部是闪存的固态硬盘，速度约1gb/s-3gb/s。: 优点：速度很快 缺点：温度高、主板m. 2口有限、价格较高 六、电源如果是ITX小机箱，那大概率只能买ITX电源，贵且选择少，推荐海盗船SF系列。另外小机箱可能不好走线，还需要买电源定制线。 功率看你的硬件，例如CPU TDP 100W，显卡 TDP 200W 那最好买550W以上的电源。预算够的话功率尽可能买大一点，这个功率不是指电脑耗电功率，而是电源最大能输出的功率，大一点风险低而且后面升级硬件方便。当然太便宜又号称高功率的电源你自己看着办吧。 电源转化效率有80PLUS的等级，即什么铜牌、银牌、金牌电源。看预算，没必要强上。 七、机箱可以没有，散热性最好；或者奢侈一点，拿个鞋盒（逃）。 看着你喜欢的买就行，注意支持的板型。一些ITX小机箱会对CPU散热器限高、显卡限长、限高。 八、散热器买盒装CPU一般会送一个风扇，不建议使用，温度压不住。有条件上水冷，没条件也买一个好一点的风冷。 注意机箱限高。 猫扇是信仰，贵但是不一定好。 "
    }, {
    "id": 24,
    "url": "/Introduction-of-Ray-Tracing/",
    "title": "简单介绍显卡新技术 RTRT, DLSS and RIS",
    "body": "2020/08/19 - 现在的新显卡除了绝对游戏性能以外，独家功能也是一大卖点。NVIDIA的20系显卡带来了RT和DLSS，而AMD的Navi显卡带来了RIS。对于消费者来说可能对这些功能不太熟悉，因此本文简单介绍这些功能背后的原理。 光线追踪：追的是什么光线自然界中，光源发出光线以后会沿直线传播，直到有阻止它前进的物体。当然，传播的过程中会遇到三种情况：折射、反射、吸收。当光源发出的一部分光线通过一系列折射反射以后进入我们的眼睛，就形成了我们看见的场景。 为了模拟更真实的光照效果，我们不难想到，让计算机模拟现实的情况，计算从光源发出的每一条光线以及它在传播过程中的各种反射折射。这对于一帧静态的图片问题不大，因为我们可以有很长的时间渲染。但是对于游戏这种实时的、并且需要每秒钟渲染几十张画面的应用来说，上述方法太复杂，因此我们必须将其简化。 上述方法最大的问题在于，从光源出发的光线，最终会有很大一部分被物体吸收而没有传到“眼睛”——也就是摄像机里面。这里的摄像机就是指观察场景的窗口，通常就是我们看到的画面。那我们可以换一个思路，如果只计算那些最后进入到摄像机的光线，那就相对于计算的每一条光线都是对我们最后渲染有意义的光线，效率达到最高。 但是那些光线是最终进入到摄像机的呢？我们只能通过逆向推导的方式得知。也就是反过来从摄像机出发，发出一条想象中的光线，通过一系列反射折射直到出现下列情况之一，则停止追踪：该光线不与任意平面相交、该光线与光源相交且光源不是反射面、达到允许的最大追踪深度。上述算法即为光线追踪的基本算法。 计算过程中，我们需要知道每一次折射、反射的系数，并通过下面几个公式推导出当前像素点的颜色值。 上图②式中，ka表示环境光反射系数，Ia表示环境光强度，Ii表示点光源，Kd表示漫反射系数，L为点光源单位方向向量，N为观察方向单位法向量，Ks表示一个固定的镜面反射系数，V为观察方向单位法向量，R为镜面反射方向向量，n为镜面反射参数。 在不考虑递归的情况下，上式可以写为： I = Idiff + Ispec = Ka*Ia + Kd*Ii*(N*L) + Ks*Ii*(N*H)^n: 该公式即表示光照表明上某点处的漫反射与镜面反射。 不只算法，还有硬件革新上述算法很早以前就提出，但是一直没有运用到游戏里面。那为什么这次NVIDIA的20系显卡可以做到光线追踪呢？ 我们不妨先看看新显卡的架构： 可以看到，Turing架构配备了RT Cores。根据NVIDIA的说法，新显卡和上一代比起来在光线追踪上快了8倍。那么问题来了，RT Cores是怎么做到硬件加速的呢？ RT Cores其实是对BVH（Bounding volume hierarchy）做了加速。BVH把集合对象包裹在树的叶子节点中，越接近根节点则包含的对象越多。下图就是一个BVH的例子。 那这和光线追踪有什么关系呢？ 光线追踪过程中，95%的时间都用于计算光线与表明求交。如果一个场景有多个对象，则可能出现计算光线与不可见对象的求交。因此我们可以将相邻对象用一个包围体包起来（即BVH），如果光线与该包围体没有交点，则不需要计算包围体里面的任何对象，大大减少计算时间。 别忘了上面架构图里面还有Tensor Cores，这就涉及到下一个技术，DLSS了。 DLSS，脑补出来的画面DLSS全称Deep Learning Super Sampling，从名字就可以看出，这是一项利用深度学习实现的技术。一句话概括就是低分辨率生成高分辨率，提升帧数。DLSS有两代，原理上不太相同。 DLSS 1. 0: 需要针对每一个游戏训练神经网络，因此这个时候只支持战地5和地铁：离去。 简单来说就是游戏厂商提供至少64张8K原始图像去训练一个模型。在游戏过程中利用1080p或者2K的图像先生成8K的图像，再缩到4K显示，以实现2倍DLSS的效果。 第一代DLSS的问题主要有以下几个：每个游戏都需要训练、只能运行在4K分辨率，清晰度不算太高。 DLSS 2. 0: 2019年8月，DLSS2. 0首先被用在Control这个游戏上，但是这一次没有使用AI技术。 2020年4月，NVIDIA发布了445. 75驱动，提供了DLSS2. 0。这个DLSS2. 0同样使用了AI技术，但是不再需要对每一个游戏进行训练。 NVIDIA使用低分辨率图像和对应的高分辨率图像训练神经网络，并将神经网络存储在驱动里面。 游戏进行时，游戏引擎将低分辨率图像给DLSS，并由DLSS生成高分辨率图像。除此之外，游戏引擎还提供了运动矢量，以便DLSS预测下一帧图像应该是什么样子。 DLSS2. 0增加了普适性，而且效果也比第一代DLSS好。 RIS：另一种方法？AMD在推出Navi显卡的同时介绍了一项新技术：RIS（Radeon Image Sharpening），也就是图像锐化。它会针对游戏中每一帧画面做对比度分析，对于对比度高的边缘部分进行锐化，让低分辨率的图像看上去更锐。 除此之外，RIS也能很好改善后期抗锯齿带来的模糊感。以FXAA为例，它会首先通过寻找深度差异较大的物体以确定边缘，然后将边缘模糊。这种技术虽然性能好，但是因为不是通过超采样得到的平滑边缘，所以整个画面会模糊。而RIS技术就可以解决这种后期抗锯齿所带来的问题。 较DLSS更优的是，此技术不需要做任何额外适配，只需要开启RIS和GPU缩放即可。 "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><span class='body'>"+ body +"</span><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-primary btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><small><span class='body'>"+ body +"</span><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});